# PrognosAI - Predictive Maintenance System ğŸ”§

## Project Overview
PrognosAI is an AI-driven predictive maintenance system that estimates the Remaining Useful Life (RUL) of industrial machinery using multivariate time-series sensor data. Built with NASA CMAPSS datasets, this system enables timely maintenance decisions, minimizes unplanned downtime, and optimizes asset utilization through deep learning techniques.

![Status](https://img.shields.io/badge/Status-Active-success)
![Python](https://img.shields.io/badge/Python-3.11%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28.0-red)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19.0-orange)
![License](https://img.shields.io/badge/License-MIT-green)

## Features

### ğŸ¯ Core Capabilities
- **ğŸ¤– AI-Powered RUL Prediction**: LSTM/GRU/CNN-LSTM models for accurate remaining useful life estimation
- **ğŸ”” Real-time Risk Assessment**: Automated alert system with warning and critical thresholds
- **ğŸ“Š Interactive Dashboard**: Professional Streamlit interface with real-time visualizations
- **ğŸ“ Multi-Dataset Support**: FD001, FD002, FD003, FD004 CMAPSS datasets
- **ğŸ”„ Simulation Mode**: Works without trained models for demonstration

### ğŸ“Š Dashboard Features
- **ğŸ“ˆ Live Metrics**: Critical/Warning/Normal alerts tracking
- **ğŸ“Š Interactive Charts**: RUL distribution, trend analysis, error visualization
- **ğŸ’¾ Export Capabilities**: CSV reports, model downloads, configuration exports
- **âš¡ Performance Monitoring**: RMSE, MAE, RÂ² scores and accuracy metrics
- **âš™ï¸ Customizable Settings**: Threshold configuration, visualization options

### ğŸ—ï¸ Project Structure
<img width="1131" height="684" alt="image" src="https://github.com/user-attachments/assets/2cbad8b3-dea4-49e3-8843-bc804f847b78" />


## ğŸ“Š Dataset Information

The system supports NASA's CMAPSS datasets:

| Dataset | Description                                          | Complexity | Training Engines | Test Engines |
|---------|------------------------------------------------------|------------|------------------|--------------|
| FD001   | Single Operating Condition, Single Fault Mode        | Low        | 100              | 100          |
| FD002   | Multiple Operating Conditions, Single Fault Mode     | Medium     | 260              | 259          |
| FD003   | Single Operating Condition, Multiple Fault Modes     | Medium     | 100              | 100          |
| FD004   | Multiple Operating Conditions, Multiple Fault Modes  | High       | 249              | 248          |

## ğŸ“– Usage Guide

### 1. Quick Start with Sample Data
- Navigate to **"Try Sample Data"** tab  
- Click **"Generate Sample Data"**  
- Select **FD001** dataset  
- Upload generated files  
- Set alert thresholds  
- Click **"Run Predictive Analysis"**

### 2. Using Your Own Data
Prepare CMAPSS-format files:
- `test_FDXXX.txt` â†’ Test sensor data  
- `RUL_FDXXX.txt` â†’ True RUL values (optional)  

In the application:
- Select dataset type (**FD001â€“FD004**)  
- Upload your files  
- Configure warning/critical thresholds  
- Run analysis  

### 3. Dashboard Navigation
- ğŸ  **Home**: Upload data and configure settings  
- ğŸ“Š **Dashboard**: View predictions, alerts, and metrics  
- ğŸ“ˆ **Analysis**: Detailed statistical analysis  
- âš™ï¸ **Settings**: System configuration and optimization

## ğŸ¤– Model Training  
Using Jupyter Notebook  


    # Open the training notebook
    jupyter notebook notebooks/prognos.ipynb

    # Follow the step-by-step training pipeline
    # 1. Install dependencies
    # 2. Upload CMAPSS datasets
    # 3. Configure model parameters
    # 4. Train LSTM/GRU/CNN-LSTM models
    # 5. Evaluate performance
    # 6. Export trained models


## ğŸ› ï¸ Training Pipeline Features


- Multiple Architectures: LSTM, GRU, CNN-LSTM with attention mechanisms

- Hyperparameter Tuning: Built-in with Keras Tuner

- Comprehensive Evaluation: RMSE, MAE, RÂ² scores, error analysis

- Production-Ready Export: Models, scalers, configurations in one package

- Visualization Suite: Training curves, prediction plots, error distributions

## ğŸ”§ Configuration  
### Key Settings in config.py 

    # Alert thresholds (customizable)
    DEFAULT_WARNING_THRESHOLD = 50  # cycles
    DEFAULT_CRITICAL_THRESHOLD = 20  # cycles

    # Performance optimization (for i3/8GB)
    MAX_MEMORY_USAGE_PERCENT = 60
    CACHE_SIZE_LIMIT_MB = 500
    SIMULATION_MODE = True  # Fallback when models unavailable

    # Visualization
    COLOR_SCHEME = {
      'critical': '#dc2626',
      'warning': '#f59e0b',
      'normal': '#10b981'
    }

### ğŸ“Š Performance Metrics
The system provides comprehensive evaluation:

| Metric          | Description                     | Target Value   |
|-----------------|---------------------------------|----------------|
| RMSE            | Root Mean Square Error          | < 30 cycles    |
| MAE             | Mean Absolute Error             | < 25 cycles    |
| RÂ² Score        | Coefficient of Determination    | > 0.85         |
| Alert Accuracy  | Correct alert classification    | > 90%          |
| Inference Time  | Prediction time per unit        | < 100ms        |


<img width="3462" height="7839" alt="interface acrhi" src="https://github.com/user-attachments/assets/5e312762-dd8d-49d1-8a29-5f7b0e41e68d" />




